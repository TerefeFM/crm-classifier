```markdown
# ğŸ§¾ Compliance Risk Management Classifier

This project implements an end-to-end machine learning pipeline using **PySpark** for compliance risk management (CRM).  
The classifier categorizes taxpayer risk levels (low, medium, high) based on structured rules and data-driven insights.  
It is designed as part of a capstone project to showcase hands-on mastery of **PySpark (RDD, DataFrame, MLlib)** and to demonstrate how AI can support real-world compliance systems.

---

## ğŸ“Œ Project Goals

- Apply PySpark end-to-end: **from ingestion â†’ preprocessing â†’ feature engineering â†’ MLlib model training â†’ deployment**.
- Build a scalable CRM classification workflow aligned with data science best practices.
- Summarize core lessons learned from CodeSignal PySpark track into a practical project.
- Provide a professional reference implementation for risk classification use cases.

---

## âš™ï¸ Tech Stack

- **Python 3.11**
- **PySpark 3.x**
- **MLlib** for machine learning
- **scikit-learn** (evaluation support)
- **JupyterLab / VS Code** for notebooks
- Git + GitHub for version control

---

## ğŸ“‚ Repository Structure

```

crm-classifier/
â”‚
â”œâ”€â”€ notebooks/              # Jupyter notebooks (step by step learning â†’ project pipeline)
â”‚   â”œâ”€â”€ 01\_data\_ingestion.ipynb
â”‚   â”œâ”€â”€ 02\_preprocessing\_rdd\_df.ipynb
â”‚   â”œâ”€â”€ 03\_feature\_engineering.ipynb
â”‚   â”œâ”€â”€ 04\_classification\_models.ipynb
â”‚   â”œâ”€â”€ 05\_model\_evaluation.ipynb
â”‚   â””â”€â”€ 06\_deployment\_demo.ipynb
â”‚
â”œâ”€â”€ data/                   # Sample / synthetic datasets
â”œâ”€â”€ src/                    # Utility scripts (ETL, feature engineering, training helpers)
â”œâ”€â”€ README.md               # Project documentation
â””â”€â”€ requirements.txt        # Dependencies

````

---

## ğŸš€ Workflow

1. **Data Ingestion**  
   Load structured data into Spark RDDs/DataFrames.  

2. **Preprocessing**  
   Handle missing values, categorical encoding, normalization.  

3. **Feature Engineering**  
   Apply compliance rules (27 rules) â†’ derive new features.  

4. **Model Training**  
   Train baseline models using **MLlib** (Logistic Regression, Decision Trees, Random Forests, etc.).  

5. **Evaluation**  
   Evaluate using **accuracy, precision, recall, F1, confusion matrix**.  

6. **Deployment Demo**  
   Export model â†’ simple API demo with **PySpark pipeline persistence**.  

---

## ğŸ“Š Results

- Achieved baseline accuracy ~XX% (to be filled with your test runs).  
- Random Forest outperformed Logistic Regression and Decision Tree.  
- Feature importance analysis revealed **rule-based features contributed most** to classification accuracy.  

---

## ğŸ› ï¸ How to Run

Clone the repo:
```bash
git clone git@github.com:TerefeFM/crm-classifier.git
cd crm-classifier
````

Create environment and install dependencies:

```bash
conda create -n crm-pyspark python=3.11 -y
conda activate crm-pyspark
pip install -r requirements.txt
```

Run notebooks:

```bash
jupyter lab
```

---

## ğŸ“– Lessons Learned

* Hands-on experience with **RDD transformations** and **DataFrames**.
* PySpark **MLlib Pipelines** make feature engineering + modeling reproducible.
* Mini-batch vs. full dataset tradeoffs when training models.
* How to persist models for later reuse.

---

## ğŸ¯ Future Work

* Integrate with **MLflow** for experiment tracking.
* Add **ensemble learning** with multiple models.
* Deploy as a **REST API** (FastAPI + Spark backend).
* Expand datasets and validate against real CRM-like data.

---

## ğŸ™Œ Acknowledgements

This project is built as part of my **CodeSignal PySpark learning track** and inspired by
ongoing **Compliance Risk Management** work with the Ministry of Revenue.
Special thanks to the **CodeSignal Community** for gamified, motivating courses! ğŸ‰

---

## ğŸ“œ License

MIT License â€“ free to use, modify, and share.

```
